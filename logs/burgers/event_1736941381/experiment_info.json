{
    "Results": {
        "BPPO": {
            "bppo_target_loss": 0.0005899071324057435,
            "bppo_energy;": 0.9722249903418124
        },
        "BC": {
            "bc_target_loss": 0.00047845469906996333,
            "bc_energy": 1.0732515372987834
        },
        "Natural Evolution": {
            "natural_target_loss": 0.0035347452562017557,
            "natural_energy": 0.0
        }
    },
    "Experiment Settings": {
        "dataset_name": "burgers",
        "seed": 20250112,
        "train_data_path": "datasets\\burgers_90000_10_128_128.pkl",
        "test_data_path": "datasets\\burgers_50_10_128_128.pkl",
        "result_dir": "logs",
        "model_save_dir": "logs\\burgers\\event_1736941381",
        "log_dir": "logs\\burgers\\event_1736941381",
        "fig_save_dir": "logs\\burgers\\event_1736941381\\figs",
        "log_freq": 1000
    },
    "Value Network Settings": {
        "v_steps": 100000,
        "v_hidden_dim": 512,
        "v_depth": 3,
        "v_lr": 0.0001,
        "v_batch_size": 64
    },
    "Q Network Settings": {
        "q_bc_steps": 100000,
        "q_pi_steps": 10,
        "q_hidden_dim": 512,
        "q_depth": 3,
        "q_lr": 0.0001,
        "q_batch_size": 64,
        "target_update_freq": 2,
        "tau": 0.005,
        "gamma": 0.99
    },
    "BC Settings": {
        "bc_steps": 100000,
        "bc_lr": 0.0001,
        "bc_hidden_dim": 512,
        "bc_depth": 3,
        "bc_batch_size": 64
    },
    "BPPO Settings": {
        "bppo_steps": 20000,
        "bppo_hidden_dim": 512,
        "bppo_depth": 3,
        "bppo_lr": 0.0001,
        "bppo_batch_size": 64,
        "clip_ratio": 0.25,
        "entropy_weight": 0.0,
        "decay": 0.96,
        "omega": 0.9,
        "is_clip_decay": true,
        "is_bppo_lr_decay": true,
        "is_update_old_policy": true
    },
    "Others": {
        "N": 90000,
        "state_dim": 128,
        "action_dim": 128,
        "nt": 10,
        "action_reward_scale": 0.01,
        "average state reward": -0.13550881102805423,
        "average action reward": -0.09178201920097839
    }
}